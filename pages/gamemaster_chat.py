import streamlit as st
import ollama
import asyncio
import threading
import json
import os
from queue import Queue
import sys

from src.my_mcp_client.client_mcp import MCPManager


# Queue pour communiquer entre threads
mcp_queue = Queue()

def init_mcp_in_thread():
    """Initialiser MCP dans un thread sÃ©parÃ©"""
    try:
        print("DEBUG: Starting MCP initialization...", flush=True)
        config_path = "C:\\Users\\Utilisateur\\Desktop\\projet_dnd\\D-D_AI_Companion\\server_config_gamemaster.json"
        
        if not os.path.exists(config_path):
            print(f"DEBUG: Config file not found: {config_path}", flush=True)
            mcp_queue.put(("error", f"Config file not found: {config_path}"))
            return
        
        print("DEBUG: Config file found, loading...", flush=True)
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            servers = list(config.get('mcpServers', {}).keys())
            print(f"DEBUG: Servers found: {servers}", flush=True)
        
        print("DEBUG: Creating event loop...", flush=True)
        # FIX: Utiliser ProactorEventLoop sur Windows
        if sys.platform == 'win32':
            loop = asyncio.ProactorEventLoop()
        else:
            loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        print("DEBUG: Creating MCPManager...", flush=True)
        mcp_manager = MCPManager()
        
        print("DEBUG: Loading servers...", flush=True)
        loop.run_until_complete(mcp_manager.load_servers(config_path))
        
        print("DEBUG: Success! Servers loaded", flush=True)
        mcp_queue.put(("success", mcp_manager))
        st.sidebar.success(f"âœ… MCP connectÃ©: {servers}")
    
    except Exception as e:
        print(f"DEBUG: Exception occurred: {type(e).__name__}: {e}", flush=True)
        import traceback
        traceback.print_exc()
        mcp_queue.put(("error", str(e)))
        st.sidebar.error(f"âŒ Erreur MCP: {str(e)}")



@st.cache_resource
def get_mcp_manager():
    """Obtenir le MCPManager (lancÃ© une seule fois)"""
    st.sidebar.info("â³ Initialisation MCP...")
    
    # Lancer le thread d'initialisation
    thread = threading.Thread(target=init_mcp_in_thread, daemon=True)
    thread.start()
    thread.join(timeout=60)  # Attendre max 60 secondes
    
    if mcp_queue.empty():
        st.sidebar.error("âŒ Timeout MCP (> 30s)")
        st.stop()
    
    status, result = mcp_queue.get()
    
    if status == "error":
        st.sidebar.error(f"âŒ {result}")
        st.stop()
    
    return result


mcp_manager = get_mcp_manager()

st.title("ğŸ² Gamemaster")
st.markdown("Je peux vous aidez avant et pendant votre campagne")

ollama_model_name = st.sidebar.selectbox(
    "ModÃ¨le Ollama",
    ["mistral:7b-instruct", "qwen3:latest", "incept5/llama3.1-claude", "deepseek-r1:latest"]
)


def call_mcp_tool_sync(tool_name: str, args: dict):
    """Appeler un tool MCP de maniÃ¨re synchrone"""
    try:
        print(f"DEBUG: Calling tool '{tool_name}' with args: {args}", flush=True)
        import sys
        
        # CrÃ©er une boucle d'Ã©vÃ©nements pour cet appel
        if sys.platform == 'win32':
            loop = asyncio.ProactorEventLoop()
        else:
            loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        print(f"DEBUG: Event loop created, calling tool...", flush=True)
        # Augmentez le timeout Ã  120 secondes (2 minutes)
        result = loop.run_until_complete(
            asyncio.wait_for(
                mcp_manager.call_tool(tool_name, args),
                timeout=120.0
            )
        )
        print(f"DEBUG: Tool completed, result length: {len(str(result))}", flush=True)
        loop.close()
        return result
    except asyncio.TimeoutError:
        print(f"DEBUG: Tool timeout after 120 seconds", flush=True)
        return f"âŒ Timeout: le tool a pris trop de temps (>120s). Essayez une requÃªte plus spÃ©cifique."
    except Exception as e:
        print(f"DEBUG: Error calling tool: {type(e).__name__}: {e}", flush=True)
        import traceback
        traceback.print_exc()
        return f"âŒ Erreur tool MCP: {str(e)}"


def generate_response(input_text):
    """GÃ©nÃ©rer une rÃ©ponse avec Ollama"""
    print(f"DEBUG: generate_response called with: {input_text[:50]}", flush=True)  # â† AJOUTEZ CETTE LIGNE

    try:
        # Construire la liste des outils disponibles
        tools_list = "\n".join([
            f"- {tool['function']['name']}: {tool['function']['description']}"
            for tool in mcp_manager.all_tools
        ])
        
        system_prompt = f"""
Vous Ãªtes un maÃ®tre du donjon (MD) ou un assistant du maÃ®tre du donjon, propulsÃ© par le serveur Gamemaster MCP. Votre rÃ´le principal est dâ€™aider les utilisateurs Ã  gÃ©rer tous les aspects de leurs campagnes de Donjons & Dragons en utilisant un ensemble riche dâ€™outils spÃ©cialisÃ©s. Vous Ãªtes une entitÃ© avec mÃ©moire, toujours active sur une seule campagne actuellement en cours.

**Principes fondamentaux :**

1. **CentrÃ© sur la campagne :** Toutes les donnÃ©es â€” personnages, PNJ, quÃªtes, lieux â€” sont stockÃ©es dans une seule Campagne active. Soyez toujours conscient du contexte de la campagne en cours. Si la demande dâ€™un utilisateur semble concerner une autre campagne, utilisez les outils list_campaigns et load_campaign pour changer de contexte.
2. **DonnÃ©es structurÃ©es :** Vous travaillez avec des modÃ¨les de donnÃ©es structurÃ©s (Character, NPC, Quest, Location, etc.). Lors de la crÃ©ation ou de la mise Ã  jour de ces entitÃ©s, remplissez-les avec le plus de dÃ©tails possible. Si lâ€™utilisateur est vague, demandez des prÃ©cisions (ex. : Â« Quelle est la classe et la race du personnage ? Quels sont ses scores de caractÃ©ristiques ? Â»).
3. **Assistance proactive :** Ne vous contentez pas dâ€™exÃ©cuter des commandes simples. RÃ©alisez des demandes complexes en chaÃ®nant les outils. Par exemple, pour Â« ajouter un nouveau personnage au groupe Â», utilisez create_character, puis Ã©ventuellement add_item_to_character pour lui donner lâ€™Ã©quipement de dÃ©part.
4. **Collecte dâ€™informations :** Avant dâ€™agir, utilisez les outils list_ et get_ pour comprendre lâ€™Ã©tat actuel. Par exemple, avant dâ€™ajouter une quÃªte, vous pourriez list_npcs pour voir qui pourrait Ãªtre le donneur de quÃªte.
5. **Gestion de lâ€™Ã©tat :** Utilisez get_game_state et update_game_state pour suivre lâ€™emplacement actuel du groupe, la date dans le jeu et le statut des combats.
6. **Soyez un conteur :** Bien que votre fonction principale soit la gestion des donnÃ©es, encadrez vos rÃ©ponses dans le contexte dâ€™un jeu de D&D. Vous nâ€™Ãªtes pas quâ€™une base de donnÃ©es ; vous Ãªtes le gardien du monde de la campagne.


**Session zÃ©ro interactive :**

Quand un utilisateur veut commencer une nouvelle campagne, tu entames une â€œSession ZÃ©roâ€.
Cette session est STRICTEMENT interactive : une seule question Ã  la fois.

Tu suis cet ordre logique :
1. nom de la campagne  
2. description / thÃ¨me  
3. nombre de joueurs  
4. crÃ©ation dâ€™un personnage Ã  la fois (nom â†’ race â†’ classe â†’ statistiques)  
5. lieu de dÃ©part  
6. premier PNJ  
7. premiÃ¨re quÃªte

IMPORTANT :
Tu ne donnes pas ces Ã©tapes Ã  lâ€™avance.
Tu ne montres jamais la liste complÃ¨te Ã  lâ€™utilisateur.
Tu poses uniquement la prochaine question pertinente selon lâ€™Ã©tape en cours.
Tu attends la rÃ©ponse avant de passer Ã  la suite.
Tu nâ€™utilises aucun exemple de dialogue dans ta rÃ©ponse.

**Guidage de la campagne en cours :**

Une fois la campagne lancÃ©e, votre rÃ´le devient gestion dynamique et soutien narratif :

1. **Monde dynamique : RÃ©agissez aux actions des joueurs et aux rÃ©sultats des outils en mettant Ã  jour le GameState, le statut des NPC, les dÃ©tails des Location et lâ€™avancement des Quest.**
2. **Journal dâ€™Ã©vÃ©nements : Chaque interaction importante, tour de combat, rencontre RP ou Ã©tape de quÃªte doit Ãªtre enregistrÃ©e via add_event pour maintenir un AdventureLog complet.**
3. **Support proactif pour le MD : Anticipez les besoins du maÃ®tre du donjon. Si un personnage subit des dÃ©gÃ¢ts, suggÃ©rez update_character_hp. Sâ€™il entre dans une nouvelle zone, proposez les dÃ©tails via get_location...**
4. **CohÃ©rence narrative : Maintenez la continuitÃ© de lâ€™histoire. RÃ©fÃ©rez-vous aux Ã©vÃ©nements passÃ©s dans le AdventureLog ou les SessionNotes pour enrichir vos descriptions.**
5. **DÃ©fi et consÃ©quences : Lorsque les joueurs entreprennent des actions, Ã©valuez les rÃ©sultats possibles et utilisez les outils appropriÃ©s pour reflÃ©ter le succÃ¨s, lâ€™Ã©chec ou le succÃ¨s partiel, en mettant Ã  jour les statistiques des personnages ou lâ€™Ã©tat du jeu.**
6. **RÃ©ponses guidÃ©es par les outils : Encadrez vos rÃ©ponses narratives autour de lâ€™exÃ©cution rÃ©ussie des outils. Par exemple, au lieu de dire Â« Les PV du personnage sont maintenant de 15 Â», dites Â« Vous soignez avec succÃ¨s [Nom du Personnage], ses points de vie sont maintenant de 15 Â».**

Tu fonctionnes en mode assistant interactif Ã©tape-par-Ã©tape.
Tu ne dois poser **quâ€™une seule question Ã  la fois** Ã  l'utilisateur.
AprÃ¨s chaque rÃ©ponse de lâ€™utilisateur, tu dois :
1. analyser sa rÃ©ponse
2. lui poser uniquement la **prochaine question logique**
3. attendre sa rÃ©ponse avant de continuer

NE DONNE JAMAIS la liste de toutes les questions Ã  l'avance.
NE PAS passer Ã  l'Ã©tape suivante tant que lâ€™utilisateur nâ€™a pas rÃ©pondu.
Continue ce processus jusquâ€™Ã  ce que toutes les informations nÃ©cessaires Ã  la crÃ©ation de la campagne soient rassemblÃ©es.


RÃˆGLES Dâ€™UTILISATION DES OUTILS :
1. Tu NE DOIS JAMAIS expliquer quel tool tu vas utiliser.
2. Tu NE DOIS JAMAIS dÃ©crire le fonctionnement dâ€™un tool.
3. Tu NE DOIS PAS dire "nous devons utiliser lâ€™outilâ€¦" ou "voici comment je le ferais".
4. Tu nâ€™utilises QUE les outils pour rÃ©pondre plus prÃ©cisÃ©ment Ã  la demande.
5. Tu ne donnes jamais de code block, jamais de backticks.
6. Tu ne fais jamais semblant dâ€™appeler un outil : tu nâ€™Ã©cris tool_call: que si tu appelles rÃ©ellement un tool MCP.
7. Si aucun outil ne peux rÃ©pondre Ã  la demande, tu rÃ©ponds normalement en expliquant que tu n'es pas certain de la rÃ©ponse en franÃ§ais.

Quand tu reÃ§ois la rÃ©ponse dâ€™un tool MCP, tu NE DOIS PAS afficher le JSON brut Ã  lâ€™utilisateur.
Tu dois toujours reformuler la rÃ©ponse de maniÃ¨re naturelle, en langage humain.
Seul le tool call doit Ãªtre en JSON (structurel) ; le rendu final NE doit jamais contenir de JSON.
Quand un tool MCP renvoie du JSON, tu ne dois jamais afficher le JSON brut Ã  lâ€™utilisateur.
Tu dois convertir automatiquement la donnÃ©e JSON en un format lisible :

- Si le JSON contient une liste, tu la convertis en liste bullet points.
- Si le JSON contient un tableau dâ€™objets, tu convertis en un tableau propre Markdown.
- Sinon, un rÃ©sumÃ© clair et reformulÃ©

Tu choisis toujours le format de prÃ©sentation le plus clair selon le contenu."""
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": input_text}
        ]
        response = ollama.chat(model=ollama_model_name, messages=messages)
        content = response.message.content.strip()
        
        print(f"DEBUG: Model response: {content[:200]}", flush=True)

        # Chercher le premier tool_call valide
        if "tool_call:" in content:
            # Extraire la premiÃ¨re ligne avec tool_call
            lines = content.split('\n')
            tool_call_line = None
            for line in lines:
                if "tool_call:" in line:
                    tool_call_line = line.strip()
                    break
            
            if tool_call_line:
                print(f"DEBUG: Found tool_call: {tool_call_line}", flush=True)
                try:
                    call_str = tool_call_line.replace("tool_call:", "").strip()
                    # Nettoyer les caractÃ¨res inutiles
                    call_str = call_str.split('\n')[0].split('```')[0].strip()
                    
                    tool_name, arg_str = call_str.split("(", 1)
                    arg_str = arg_str.rstrip(")")
                    
                    print(f"DEBUG: Tool name: {tool_name}, Args: {arg_str}", flush=True)
                    
                    args = {}
                    if arg_str.strip():
                        for item in arg_str.split(","):
                            if "=" in item:
                                k, v = item.split("=", 1)
                                args[k.strip()] = v.strip().strip("'\"")
                    
                    print(f"DEBUG: Parsed args: {args}", flush=True)
                    tool_result = call_mcp_tool_sync(tool_name, args)
                    return tool_result
                except (ValueError, IndexError) as ve:
                    print(f"DEBUG: Parse error: {ve}", flush=True)
                    return f"âŒ Erreur parsing tool_call: {str(ve)}"
        
        return content
    
    except Exception as e:
        print(f"DEBUG: Exception in generate_response: {type(e).__name__}: {e}", flush=True)
        import traceback
        traceback.print_exc()
        return f"âŒ Erreur Ollama: {str(e)}"


def save_feedback(index):
    st.session_state.history[index]["feedback"] = st.session_state[f"feedback_{index}"]


if "history" not in st.session_state:
    st.session_state.history = []

for i, message in enumerate(st.session_state.history):
    with st.chat_message(message["role"]):
        st.write(message["content"])
        if message["role"] == "assistant":
            feedback = message.get("feedback", None)
            st.session_state[f"feedback_{i}"] = feedback
            st.feedback(
                "thumbs",
                key=f"feedback_{i}",
                disabled=feedback is not None,
                on_change=save_feedback,
                args=[i],
            )

if prompt := st.chat_input("Say something"):
    with st.chat_message("user"):
        st.write(prompt)
    st.session_state.history.append({"role": "user", "content": prompt})
    
    with st.chat_message("assistant"):
        with st.spinner("â³ GÃ©nÃ©ration en cours..."):
            response = generate_response(prompt)
        st.write(response)
        st.feedback(
            "thumbs",
            key=f"feedback_{len(st.session_state.history)}",
            on_change=save_feedback,
            args=[len(st.session_state.history)],
        )
    st.session_state.history.append({"role": "assistant", "content": response})